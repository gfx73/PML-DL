{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gfx73/PML-DL/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AD-HO1iDuN8y",
        "outputId": "53a806fa-4441-49c7-995a-8ee540263ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting allennlp\n",
            "  Downloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n",
            "\u001b[K     |████████████████████████████████| 730 kB 34.5 MB/s \n",
            "\u001b[?25hCollecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 47.1 MB/s \n",
            "\u001b[?25hCollecting fairscale==0.4.6\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 71.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting h5py>=3.6.0\n",
            "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (9.0.0)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.17.3)\n",
            "Collecting spacy<3.4,>=2.1.0\n",
            "  Downloading spacy-3.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 32.7 MB/s \n",
            "\u001b[?25hCollecting wandb<0.13.0,>=0.10.0\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 60.7 MB/s \n",
            "\u001b[?25hCollecting termcolor==1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: torchvision<0.14.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.13.1+cu113)\n",
            "Collecting filelock<3.8,>=3.3\n",
            "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch<1.13.0,>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.64.1)\n",
            "Collecting base58>=2.1.1\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting lmdb>=1.2.1\n",
            "  Downloading lmdb-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 67.0 MB/s \n",
            "\u001b[?25hCollecting cached-path<1.2.0,>=1.1.3\n",
            "  Downloading cached_path-1.1.6-py3-none-any.whl (26 kB)\n",
            "Collecting pytest>=6.2.5\n",
            "  Downloading pytest-7.2.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 74.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.16\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 74.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.7)\n",
            "Collecting transformers<4.21,>=4.1\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 58.5 MB/s \n",
            "\u001b[?25hCollecting requests>=2.28\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece>=0.1.96\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 56.8 MB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting traitlets>5.1.1\n",
            "  Downloading traitlets-5.5.0-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.3.6)\n",
            "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.21.6)\n",
            "Collecting boto3<2.0,>=1.0\n",
            "  Downloading boto3-1.25.5-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 55.8 MB/s \n",
            "\u001b[?25hCollecting rich<13.0,>=12.1\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 73.2 MB/s \n",
            "\u001b[?25hCollecting google-cloud-storage<3.0,>=1.32.0\n",
            "  Downloading google_cloud_storage-2.5.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting botocore<1.29.0,>=1.28.5\n",
            "  Downloading botocore-1.28.5-py3-none-any.whl (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 58.0 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.29.0,>=1.28.5->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 73.4 MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<3.0dev,>=2.3.0\n",
            "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.31.6)\n",
            "Collecting google-resumable-media>=2.3.2\n",
            "  Downloading google_resumable_media-2.4.0-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.56.4)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2022.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.2.4)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.13.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.8)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->allennlp) (22.1.0)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting exceptiongroup>=1.0.0rc8\n",
            "  Downloading exceptiongroup-1.0.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.0.16->allennlp) (3.10.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp) (2022.9.24)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.1.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.10)\n",
            "Collecting thinc<8.1.0,>=8.0.14\n",
            "  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.6.2)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4,>=2.1.0->allennlp) (5.2.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (7.1.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 73.9 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 67.5 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.0.1)\n",
            "Building wheels for collected packages: fairscale, termcolor, jsonnet, pathtools, sacremoses\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307252 sha256=ac95404431fe7ea4816d71249d1c3b032424efa84804a57b5e78afd71e339fbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=952d8ba99c38aa4889b9e623fdc8c95990e40fbd44eff999544cd144c2f959ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp37-cp37m-linux_x86_64.whl size=3997193 sha256=bf1b4d00f1429f64735cc2aa33eaa8d0cbf000636c08e02712d821310247455c\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/6b/48/a168ed5f8d01c50268605eff341c29126286763607bf707e3b\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=c97953bce8219af58a621b8de46d6ecfcecf0f69dc92441f831baeb95fb792ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=a7f58d3179212ba38c9ac2c9e71a6b76f38f0a8044125933d57fd53dc1774b65\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built fairscale termcolor jsonnet pathtools sacremoses\n",
            "Installing collected packages: urllib3, requests, jmespath, smmap, google-crc32c, botocore, s3transfer, pydantic, google-resumable-media, google-cloud-core, gitdb, filelock, commonmark, tokenizers, thinc, shortuuid, setproctitle, sentry-sdk, rich, pluggy, pathtools, iniconfig, huggingface-hub, google-cloud-storage, GitPython, exceptiongroup, docker-pycreds, boto3, wandb, transformers, traitlets, termcolor, tensorboardX, spacy, sentencepiece, sacremoses, pytest, lmdb, jsonnet, h5py, fairscale, cached-path, base58, allennlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.2\n",
            "    Uninstalling pydantic-1.10.2:\n",
            "      Successfully uninstalled pydantic-1.10.2\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.8.0\n",
            "    Uninstalling filelock-3.8.0:\n",
            "      Successfully uninstalled filelock-3.8.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.5\n",
            "    Uninstalling thinc-8.1.5:\n",
            "      Successfully uninstalled thinc-8.1.5\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.1.1\n",
            "    Uninstalling traitlets-5.1.1:\n",
            "      Successfully uninstalled traitlets-5.1.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.0.1\n",
            "    Uninstalling termcolor-2.0.1:\n",
            "      Successfully uninstalled termcolor-2.0.1\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.2\n",
            "    Uninstalling spacy-3.4.2:\n",
            "      Successfully uninstalled spacy-3.4.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: lmdb\n",
            "    Found existing installation: lmdb 0.99\n",
            "    Uninstalling lmdb-0.99:\n",
            "      Successfully uninstalled lmdb-0.99\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.4.0 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.29 allennlp-2.10.1 base58-2.1.1 boto3-1.25.5 botocore-1.28.5 cached-path-1.1.6 commonmark-0.9.1 docker-pycreds-0.4.0 exceptiongroup-1.0.0 fairscale-0.4.6 filelock-3.7.1 gitdb-4.0.9 google-cloud-core-2.3.2 google-cloud-storage-2.5.0 google-crc32c-1.5.0 google-resumable-media-2.4.0 h5py-3.7.0 huggingface-hub-0.10.1 iniconfig-1.1.1 jmespath-1.0.1 jsonnet-0.19.1 lmdb-1.3.0 pathtools-0.1.2 pluggy-1.0.0 pydantic-1.8.2 pytest-7.2.0 requests-2.28.1 rich-12.6.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 sentry-sdk-1.10.1 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 spacy-3.3.1 tensorboardX-2.5.1 termcolor-1.1.0 thinc-8.0.17 tokenizers-0.12.1 traitlets-5.5.0 transformers-4.20.1 urllib3-1.26.12 wandb-0.12.21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install allennlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8OFl6YZUbxK",
        "outputId": "35c2e85a-f980-4234-c208-06df0109865b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch==1.12.1+cu113 in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision==0.13.1+cu113 in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio==0.12.1 in /usr/local/lib/python3.7/dist-packages (0.12.1+cu113)\n",
            "Collecting torchdata==0.4.1\n",
            "  Downloading torchdata-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 18.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchtext==0.13.1 in /usr/local/lib/python3.7/dist-packages (0.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1+cu113) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.13.1+cu113) (2.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.13.1+cu113) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.13.1+cu113) (7.1.2)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata==0.4.1) (1.26.12)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.1) (4.64.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1+cu113) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1+cu113) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1+cu113) (2.10)\n",
            "Installing collected packages: portalocker, torchdata\n",
            "Successfully installed portalocker-2.6.0 torchdata-0.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 torchdata==0.4.1 torchtext==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "TOK_IDS_PRECOMPUTED = False\n",
        "CLASSIFIER_PRETRAINED = True"
      ],
      "metadata": {
        "id": "1lUn0gjBYdXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JXDZ44Uvc_P3",
        "outputId": "985815e7-52fe-46b0-f9f8-edaa359b2135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ADLyYv5gTXie"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "\n",
        "IMDB_train_iter, IMDB_test_iter = IMDB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MacnAo18Tci1",
        "outputId": "14b64f00-41cd-4dce-aceb-7c392ee17bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [00:25, 973.66it/s] \n",
            "25000it [00:15, 1601.17it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import gc\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def get_labels_and_text(datasplit):\n",
        "  tokens, labels = [], []\n",
        "  for label, text in tqdm(datasplit):\n",
        "    tokens.append(tokenizer(text))\n",
        "    labels.append(label=='pos')\n",
        "  return tokens, labels\n",
        "\n",
        "train_tokens, train_labels = get_labels_and_text(IMDB_train_iter)\n",
        "test_tokens, test_labels = get_labels_and_text(IMDB_test_iter)\n",
        "\n",
        "del IMDB_train_iter\n",
        "del IMDB_test_iter\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpwit5nSU1hz",
        "outputId": "80c1d0e0-c2ff-4f56-a265-a06dfc9386ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2752\n"
          ]
        }
      ],
      "source": [
        "def get_max_len(all_tokens):\n",
        "  max_len = 0\n",
        "  for tokens_split in all_tokens:\n",
        "    for tokens in tokens_split:\n",
        "      max_len = max(max_len, len(tokens))\n",
        "  return max_len\n",
        "\n",
        "\n",
        "max_len = get_max_len((train_tokens, test_tokens))\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VgK8v-gDvn5e"
      },
      "outputs": [],
      "source": [
        "# from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "# import torch\n",
        "\n",
        "\n",
        "# def save_tok_ids(all_tokens, filename_prefix, shard_size=5000):\n",
        "#   all_tok_ids = []\n",
        "#   for idx, tokens in tqdm(enumerate(all_tokens), total=len(all_tokens)):\n",
        "#     tok_ids = (batch_to_ids([tokens])[0])\n",
        "#     all_tok_ids.append(tok_ids)\n",
        "\n",
        "#     if (idx + 1) % shard_size == 0 or (idx + 1) == len(all_tokens):\n",
        "#       torch.save(all_tok_ids, f\"{filename_prefix}{idx // shard_size}.pt\")\n",
        "#       del all_tok_ids\n",
        "#       gc.collect()\n",
        "#       all_tok_ids = []\n",
        "#   return all_tok_ids\n",
        "\n",
        "# train_filename_prefix = 'train_tok_ids'\n",
        "# test_filename_prefix = 'test_tok_ids'\n",
        "# # val_filename_prefix = 'val_tok_ids'\n",
        "\n",
        "# if not TOK_IDS_PRECOMPUTED:\n",
        "#   train_tok_ids = save_tok_ids(train_tokens, train_filename_prefix)\n",
        "#   del train_tokens\n",
        "#   gc.collect()\n",
        "\n",
        "#   test_tok_ids = save_tok_ids(test_tokens, test_filename_prefix)\n",
        "#   del test_tokens\n",
        "#   gc.collect()\n",
        "\n",
        "#   # val_tok_ids = save_tok_ids(val_tokens, val_filename_prefix)\n",
        "#   # del val_tokens\n",
        "#   # gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "# from torch.utils.data import Dataset, DataLoader, random_split\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# torch.manual_seed(11)\n",
        "\n",
        "# class dataset(Dataset):\n",
        "#   def __init__(self, labels, filename_prefix, max_len, shard_size=5000):\n",
        "#     self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "#     self.length = self.labels.shape[0]\n",
        "#     self.filename_prefix = filename_prefix\n",
        "#     self.shard_size=shard_size\n",
        "#     self.cur_shard = None\n",
        "#     self.cur_shard_idx = None\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#     tok_ids = self.__get_tok_ids__(idx)\n",
        "#     if tok_ids.shape[0] > max_len:\n",
        "#       tok_ids = tok_ids[:max_len,:]\n",
        "#     else:\n",
        "#       tok_ids = torch.concat((tok_ids, torch.zeros((max_len - tok_ids.shape[0], 50)).type_as(tok_ids)))\n",
        "    \n",
        "#     return tok_ids.to(device), self.labels[idx].to(device)\n",
        "\n",
        "#   def __get_tok_ids__(self, idx):\n",
        "#     self.__reload_shard__(idx)\n",
        "#     return self.cur_shard[idx % self.shard_size]\n",
        "\n",
        "#   def __reload_shard__(self, idx):\n",
        "#     shard_idx = idx // self.shard_size\n",
        "#     if self.cur_shard_idx == shard_idx:\n",
        "#       return\n",
        "    \n",
        "#     del self.cur_shard\n",
        "#     gc.collect()\n",
        "#     self.cur_shard = torch.load(f\"{self.filename_prefix}{shard_idx}.pt\")\n",
        "#     self.cur_shard_idx = shard_idx\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return self.length\n",
        "\n",
        "\n",
        "# trainset = dataset(train_labels, train_filename_prefix, max_len)\n",
        "# testset = dataset(test_labels, test_filename_prefix, max_len)\n",
        "# valset, testset = random_split(testset, [0.02, 0.98])\n",
        "\n",
        "# BATCH_SIZE = 8\n",
        "# trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "# valloader = DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "# testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "xT-BD8AIYdXK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6kW_R9PkXrdz",
        "outputId": "a5c0f420-b0d8-4e76-e179-8613a16b06ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-75c9ed0e7840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mvalset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.98\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36mrandom_split\u001b[0;34m(dataset, lengths, generator)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;31m# Cannot verify that dataset is Sized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sum of input lengths does not equal the length of the input dataset!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
          ]
        }
      ],
      "source": [
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.manual_seed(11)\n",
        "\n",
        "\n",
        "class dataset(Dataset):\n",
        "  def __init__(self, tokens, labels, batch_to_ids, max_len):\n",
        "    self.tokens = tokens\n",
        "    self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "    self.length = self.labels.shape[0]\n",
        "    self.batch_to_ids = batch_to_ids\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    tok_ids = self.batch_to_ids([self.tokens[idx]])[0]\n",
        "\n",
        "    if tok_ids.shape[0] > self.max_len:\n",
        "      tok_ids = tok_ids[:self.max_len,:]\n",
        "    else:\n",
        "      tok_ids = torch.concat((tok_ids, torch.zeros((self.max_len - tok_ids.shape[0], 50)).type_as(tok_ids)))\n",
        "\n",
        "    return tok_ids.to(device), self.labels[idx].to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "\n",
        "trainset = dataset(train_tokens, train_labels, batch_to_ids, max_len)\n",
        "testset = dataset(test_tokens, test_labels, batch_to_ids, max_len)\n",
        "\n",
        "valset_size = int(len(train_set) * 0.8)\n",
        "test_set_size = len(train_set) - valset_size\n",
        "valset, testset = random_split(testset, [valset_size, test_set_size], generator=torch.Generator())\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UECEqirPD3_2"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, input_shape, elmo):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.input_shape = input_shape\n",
        "    self.elmo = elmo\n",
        "    self.fc1 = nn.Linear(input_shape, 1)\n",
        "    \n",
        "  def forward(self, input):\n",
        "    embs = self.elmo(input)['elmo_representations'][0]\n",
        "    reshaped = embs.view((-1, self.input_shape))\n",
        "    x = torch.sigmoid(self.fc1(reshaped))\n",
        "    return x\n",
        "\n",
        "\n",
        "if CLASSIFIER_PRETRAINED:\n",
        "  if IN_COLAB:\n",
        "    classifier = torch.load('/content/drive/MyDrive/PML&DL/Assignment2/elmo_classifier.pt')\n",
        "else:\n",
        "  if IN_COLAB:\n",
        "    options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "    weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "    elmo = Elmo(options_file, weight_file, dropout=0, requires_grad=False, num_output_representations=1).to(device)\n",
        "  else:\n",
        "    options_file = \"options.json\"\n",
        "    weight_file = \"weights.hdf5\"\n",
        "    elmo = Elmo(options_file, weight_file, dropout=0, requires_grad=False, num_output_representations=1).to(device)\n",
        "  classifier = Classifier(1024 * max_len, elmo=elmo).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "sum(p.numel() for p in classifier.elmo.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "kp9_BR9fYdXN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "l2_penalty = 0.001\n",
        "\n",
        "optimizer = torch.optim.RMSprop(classifier.parameters(), lr=learning_rate, weight_decay=l2_penalty)\n",
        "loss_fn = F.binary_cross_entropy_with_logits"
      ],
      "metadata": {
        "id": "EHA4Iw4eYdXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "EKin9GVRYdXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "\n",
        "def eval_model(model, data, loss_fn):\n",
        "  acc_metric = torchmetrics.Accuracy().to(device)\n",
        "  prec_metric = torchmetrics.Precision().to(device)\n",
        "  rec_metric = torchmetrics.Recall().to(device)\n",
        "  f1_metric = torchmetrics.F1Score().to(device)\n",
        "  running_loss = 0\n",
        "  for x, y in tqdm(data):\n",
        "    with torch.no_grad():\n",
        "      y = y.reshape(-1, 1)\n",
        "      with torch.autocast(device_type=device, dtype=torch.float16):\n",
        "        preds = model(x)\n",
        "        loss = loss_fn(preds, y)\n",
        "\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      \n",
        "      y = y.type(torch.int8)\n",
        "      acc_metric(preds.round(), y)\n",
        "      prec_metric(preds.round(), y)\n",
        "      rec_metric(preds.round(), y)\n",
        "      f1_metric(preds.round(), y)\n",
        "\n",
        "      print(y)\n",
        "      print(preds.round())\n",
        "      print(acc_metric.compute())\n",
        "\n",
        "  loss = running_loss / len(data)\n",
        "  acc = acc_metric.compute().item()\n",
        "  prec = prec_metric.compute().item()\n",
        "  rec = rec_metric.compute().item()\n",
        "  f1 = f1_metric.compute().item()\n",
        "  return loss, acc, prec, rec, f1\n",
        "\n",
        "loss, acc, prec, rec, f1 = eval_model(classifier, valloader, loss_fn)\n",
        "print(loss, acc, prec, rec, f1)"
      ],
      "metadata": {
        "id": "1w1z74paYdXP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2CyZ4zFLd9Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLvBW73M21-c",
        "outputId": "7eabc579-441e-4444-c026-56b760d84ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/782 [00:30<6:39:09, 30.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 0\tloss: 0.9711554050445557\tthis iteration loss: 0.9711554050445557\taccuracy: 0.65625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 51/782 [04:23<59:30,  4.88s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 50\tloss: 0.6985983240838144\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9932598039215687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 101/782 [08:03<49:50,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 100\tloss: 0.6958997391238071\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9965965346534653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 151/782 [11:47<43:22,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 150\tloss: 0.6949882965214205\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9977235099337748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 201/782 [15:55<38:58,  4.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 200\tloss: 0.694530307950072\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9982898009950248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 251/782 [19:47<43:10,  4.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 250\tloss: 0.6942547849449978\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9986304780876494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 301/782 [23:34<35:40,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 300\tloss: 0.6940707978220081\tthis iteration loss: 0.6931471824645996\taccuracy: 0.998857973421927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 351/782 [27:43<32:28,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 350\tloss: 0.6939394270252978\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9990206552706553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████▏    | 401/782 [31:31<30:21,  4.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 400\tloss: 0.6938407345305655\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9732699501246883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 451/782 [35:32<25:29,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 450\tloss: 0.6937638395641437\tthis iteration loss: 0.6931471824645996\taccuracy: 0.8653686252771619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 501/782 [39:46<24:01,  5.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 500\tloss: 0.6937022003347051\tthis iteration loss: 0.693146824836731\taccuracy: 0.7790044910179641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 551/782 [43:43<18:57,  4.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 550\tloss: 0.693650648187163\tthis iteration loss: 0.693146288394928\taccuracy: 0.7083144283121597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 601/782 [47:24<13:55,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 600\tloss: 0.6936086258555014\tthis iteration loss: 0.6931471824645996\taccuracy: 0.6493864392678869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 651/782 [51:47<10:50,  4.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 650\tloss: 0.692640931375565\tthis iteration loss: 0.3132617473602295\taccuracy: 0.6018145161290323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 701/782 [55:32<06:12,  4.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 700\tloss: 0.6655810751690504\tthis iteration loss: 0.3132617473602295\taccuracy: 0.630215763195435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 751/782 [59:24<02:24,  4.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 750\tloss: 0.6421244010309405\tthis iteration loss: 0.3132617473602295\taccuracy: 0.6548352197070573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [1:01:41<00:00,  4.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\ttrain loss : 0.6290876514771405\ttrain accuracy : 0.6682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [01:04<00:00,  4.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\tval loss: 1.3129631280899048\tval acc: 0.0\tval prec: 0.0\tval rec: 0.0\tval f1: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/782 [00:32<7:01:38, 32.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 0\tloss: 1.3132617473602295\tthis iteration loss: 1.3132617473602295\taccuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 51/782 [04:25<59:34,  4.89s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 50\tloss: 1.2149251711134816\tthis iteration loss: 0.6931856870651245\taccuracy: 0.1568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 101/782 [08:04<49:04,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 100\tloss: 0.9566466589965442\tthis iteration loss: 0.6931599378585815\taccuracy: 0.5742574257425742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 151/782 [11:49<43:06,  4.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 150\tloss: 0.8694047367335945\tthis iteration loss: 0.6931594610214233\taccuracy: 0.7152317880794702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 201/782 [15:56<38:57,  4.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 200\tloss: 0.8255782406128461\tthis iteration loss: 0.6933270692825317\taccuracy: 0.7860696517412935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 251/782 [19:48<43:14,  4.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 250\tloss: 0.7992086270415926\tthis iteration loss: 0.6931647658348083\taccuracy: 0.8286852589641435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 301/782 [23:35<35:41,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 300\tloss: 0.7816015301748763\tthis iteration loss: 0.693183958530426\taccuracy: 0.8571428571428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 351/782 [27:44<32:27,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 350\tloss: 0.7690148593014122\tthis iteration loss: 0.6931698322296143\taccuracy: 0.8774928774928775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████▏    | 401/782 [31:33<30:20,  4.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 400\tloss: 0.7538156167527387\tthis iteration loss: 0.3140682578086853\taccuracy: 0.8820137157107232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 451/782 [35:33<25:29,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 450\tloss: 0.7049802066613724\tthis iteration loss: 0.3132617473602295\taccuracy: 0.8950942350332595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 501/782 [39:46<24:01,  5.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 500\tloss: 0.6658932373314322\tthis iteration loss: 0.31341809034347534\taccuracy: 0.9055638722554891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 551/782 [43:43<18:35,  4.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 550\tloss: 0.633899870130847\tthis iteration loss: 0.313352108001709\taccuracy: 0.9141333938294011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 601/782 [47:24<13:49,  4.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 600\tloss: 0.6072272603801404\tthis iteration loss: 0.31328636407852173\taccuracy: 0.9212770382695508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 651/782 [51:47<10:54,  5.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 650\tloss: 0.5846520603710239\tthis iteration loss: 0.31329047679901123\taccuracy: 0.9273233486943164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 701/782 [55:32<06:14,  4.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 700\tloss: 0.5652972725505666\tthis iteration loss: 0.31328636407852173\taccuracy: 0.9325071326676176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 751/782 [59:23<02:25,  4.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\titeration: 750\tloss: 0.5485195835008126\tthis iteration loss: 0.313265860080719\taccuracy: 0.9370006657789614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [1:01:40<00:00,  4.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\ttrain loss : 0.5391950869499265\ttrain accuracy : 0.93944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [01:04<00:00,  4.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\tval loss: 1.313014179468155\tval acc: 0.0\tval prec: 0.0\tval rec: 0.0\tval f1: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/782 [00:30<6:39:32, 30.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2\titeration: 0\tloss: 1.3132617473602295\tthis iteration loss: 1.3132617473602295\taccuracy: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 51/782 [04:23<59:31,  4.89s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2\titeration: 50\tloss: 0.7696888925982457\tthis iteration loss: 0.6931514143943787\taccuracy: 0.8774509803921569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 101/782 [08:02<49:03,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2\titeration: 100\tloss: 0.7318018049296766\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9381188118811881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 151/782 [11:47<43:11,  4.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2\titeration: 150\tloss: 0.7190023419872814\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9586092715231788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 201/782 [15:54<38:54,  4.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2\titeration: 200\tloss: 0.7125729325398877\tthis iteration loss: 0.6931651830673218\taccuracy: 0.9689054726368159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 251/782 [19:46<43:11,  4.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2\titeration: 250\tloss: 0.7087053946289883\tthis iteration loss: 0.6931471824645996\taccuracy: 0.9750996015936255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 267/782 [21:00<39:31,  4.60s/it]"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "# torch.autograd.set_detect_anomaly(True)\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "\n",
        "best_val_loss = 1e+8\n",
        "for epoch in range(epochs):\n",
        "  running_loss, correct, total = 0, 0, 0\n",
        "  for iteration, (x_train ,y_train) in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
        "    optimizer.zero_grad()\n",
        "    y_train = y_train.reshape(-1,1)\n",
        "    with torch.autocast(device_type=device, dtype=torch.float16):\n",
        "      preds = classifier(x_train)\n",
        "      loss = loss_fn(preds, y_train)\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    total += y_train.shape[0]\n",
        "    correct += preds.round().eq(y_train).sum().item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iteration % 50 == 0:\n",
        "      _loss = running_loss / (iteration + 1)\n",
        "      acc = correct / total\n",
        "      print(\"epoch: {}\\titeration: {}\\tloss: {}\\tthis iteration loss: {}\\taccuracy: {}\".format(epoch, iteration, _loss, loss, acc))\n",
        "\n",
        "\n",
        "  loss = running_loss / len(trainloader)\n",
        "  acc = correct / total\n",
        "  train_losses.append(loss)\n",
        "  train_accs.append(acc)\n",
        "  print(\"epoch {}\\ttrain loss : {}\\ttrain accuracy : {}\".format(epoch, loss, acc))\n",
        "\n",
        "  loss, acc, prec, rec, f1 = eval_model(classifier, valloader, loss_fn)\n",
        "  print(\"epoch: {}\\tval loss: {}\\tval acc: {}\\tval prec: {}\\tval rec: {}\\tval f1: {}\".format(epoch, loss, acc, prec, rec, f1))\n",
        "  if IN_COLAB:\n",
        "    if best_val_loss > loss:\n",
        "      torch.save(classifier, '/content/drive/MyDrive/PML&DL/Assignment2/elmo_classifier.pt')\n",
        "      best_val_loss = loss\n",
        "  else:\n",
        "    torch.save(classifier, f'classifier{epoch}.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  !kill $(ps aux | awk '{print $2}')"
      ],
      "metadata": {
        "id": "fNyFSp2wYdXQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}