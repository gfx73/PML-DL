{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gfx73/PML-DL/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AD-HO1iDuN8y",
    "outputId": "53a806fa-4441-49c7-995a-8ee540263ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: allennlp in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: typer>=0.4.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.7.3 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (1.9.3)\n",
      "Requirement already satisfied: wandb<0.13.0,>=0.10.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (0.12.21)\n",
      "Requirement already satisfied: numpy>=1.21.4 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (1.23.4)\n",
      "Requirement already satisfied: h5py>=3.6.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (3.7.0)\n",
      "Requirement already satisfied: fairscale==0.4.6 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (0.4.6)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (1.1.3)\n",
      "Requirement already satisfied: tensorboardX>=1.2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (2.5.1)\n",
      "Requirement already satisfied: cached-path<1.2.0,>=1.1.3 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (1.1.6)\n",
      "Requirement already satisfied: filelock<3.8,>=3.3 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (3.7.1)\n",
      "Requirement already satisfied: nltk>=3.6.5 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (3.7)\n",
      "Requirement already satisfied: transformers<4.21,>=4.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (4.20.1)\n",
      "Requirement already satisfied: traitlets>5.1.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (5.5.0)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (3.19.6)\n",
      "Requirement already satisfied: requests>=2.28 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (4.64.1)\n",
      "Requirement already satisfied: torch<1.13.0,>=1.10.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (1.12.1+cu113)\n",
      "Requirement already satisfied: torchvision<0.14.0,>=0.8.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (0.13.1+cu113)\n",
      "Requirement already satisfied: spacy<3.4,>=2.1.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (3.3.1)\n",
      "Requirement already satisfied: termcolor==1.1.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (1.1.0)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (0.1.97)\n",
      "Requirement already satisfied: more-itertools>=8.12.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (9.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.16 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (0.10.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (0.3.6)\n",
      "Requirement already satisfied: sacremoses in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (0.0.53)\n",
      "Requirement already satisfied: lmdb>=1.2.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (1.3.0)\n",
      "Requirement already satisfied: pytest>=6.2.5 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (7.2.0)\n",
      "Requirement already satisfied: base58>=2.1.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from allennlp) (2.1.1)\n",
      "Requirement already satisfied: rich<13.0,>=12.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (12.6.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (2.5.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (1.25.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from huggingface-hub>=0.0.16->allennlp) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from huggingface-hub>=0.0.16->allennlp) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from huggingface-hub>=0.0.16->allennlp) (21.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from nltk>=3.6.5->allennlp) (2022.9.13)\n",
      "Requirement already satisfied: click in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from nltk>=3.6.5->allennlp) (8.1.3)\n",
      "Requirement already satisfied: joblib in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from nltk>=3.6.5->allennlp) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from pytest>=6.2.5->allennlp) (21.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from pytest>=6.2.5->allennlp) (1.0.0)\n",
      "Requirement already satisfied: iniconfig in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from pytest>=6.2.5->allennlp) (1.1.1)\n",
      "Requirement already satisfied: colorama in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from pytest>=6.2.5->allennlp) (0.4.5)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from pytest>=6.2.5->allennlp) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from requests>=2.28->allennlp) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from requests>=2.28->allennlp) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from requests>=2.28->allennlp) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from requests>=2.28->allennlp) (1.26.12)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from scikit-learn>=1.0.1->allennlp) (3.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (0.6.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (1.8.2)\n",
      "Requirement already satisfied: setuptools in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (65.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (8.0.17)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.5)\n",
      "Requirement already satisfied: jinja2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (9.3.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from transformers<4.21,>=4.1->allennlp) (0.12.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.10.1)\n",
      "Requirement already satisfied: pathtools in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.3.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
      "Requirement already satisfied: six>=1.13.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.16.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.0.9)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (3.1.29)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.29.0,>=1.28.4 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.28.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (4.0.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.3.2)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.13.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.10.2)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.0.16->allennlp) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4,>=2.1.0->allennlp) (5.2.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.11.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from botocore<1.29.0,>=1.28.4->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.8.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (5.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.56.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (5.2.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from google-resumable-media>=2.3.2->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8OFl6YZUbxK",
    "outputId": "35c2e85a-f980-4234-c208-06df0109865b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch==1.12.1+cu113 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (1.12.1+cu113)\n",
      "Requirement already satisfied: torchvision==0.13.1+cu113 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (0.13.1+cu113)\n",
      "Requirement already satisfied: torchaudio==0.12.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (0.12.1+cu113)\n",
      "Requirement already satisfied: torchdata==0.4.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: torchtext==0.13.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torch==1.12.1+cu113) (4.3.0)\n",
      "Requirement already satisfied: requests in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchvision==0.13.1+cu113) (2.28.1)\n",
      "Requirement already satisfied: numpy in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchvision==0.13.1+cu113) (1.23.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchvision==0.13.1+cu113) (9.3.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchdata==0.4.1) (1.26.12)\n",
      "Requirement already satisfied: portalocker>=2.0.0 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchdata==0.4.1) (2.6.0)\n",
      "Requirement already satisfied: tqdm in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchtext==0.13.1) (4.64.1)\n",
      "Requirement already satisfied: pywin32>=226 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from portalocker>=2.0.0->torchdata==0.4.1) (302)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from requests->torchvision==0.13.1+cu113) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from requests->torchvision==0.13.1+cu113) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from requests->torchvision==0.13.1+cu113) (2.0.4)\n",
      "Requirement already satisfied: colorama in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from tqdm->torchtext==0.13.1) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 torchdata==0.4.1 torchtext==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sys\n",
    "CLASSIFIER_PRETRAINED = False\n",
    "MAX_SEQ_LEN = 1000\n",
    "\n",
    "# PRECOMPUTE_TOK_IDS = False\n",
    "# TOK_IDS_PRECOMPUTED = True\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "  PATH_TO_SAVE_ELMO_CLASSIFIER = '/content/drive/MyDrive/PML&DL/Assignment2/elmo_classifier.pt'\n",
    "else:\n",
    "  PATH_TO_SAVE_ELMO_CLASSIFIER = 'elmo_classifier.pt'"
   ],
   "metadata": {
    "id": "1lUn0gjBYdXG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "JXDZ44Uvc_P3",
    "outputId": "985815e7-52fe-46b0-f9f8-edaa359b2135",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ADLyYv5gTXie"
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "\n",
    "IMDB_train_iter, IMDB_test_iter = IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MacnAo18Tci1",
    "outputId": "14b64f00-41cd-4dce-aceb-7c392ee17bde",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25000it [00:03, 6374.72it/s]\n",
      "25000it [00:03, 6505.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import gc\n",
    "import random\n",
    "\n",
    "\n",
    "random.seed(11)\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def get_labels_and_text(datasplit):\n",
    "  tokens, labels = [], []\n",
    "  for label, text in tqdm(datasplit):\n",
    "    tokens.append(tokenizer(text))\n",
    "    labels.append(label=='pos')\n",
    "  return tokens, labels\n",
    "\n",
    "train_tokens, train_labels = get_labels_and_text(IMDB_train_iter)\n",
    "test_tokens, test_labels = get_labels_and_text(IMDB_test_iter)\n",
    "\n",
    "sample_tokens_and_labels = lambda tokens, labels: zip(*random.sample(list(zip(tokens, labels)), len(labels)))\n",
    "\n",
    "train_tokens, train_labels = sample_tokens_and_labels(train_tokens, train_labels)\n",
    "test_tokens, test_labels = sample_tokens_and_labels(test_tokens, test_labels)\n",
    "\n",
    "# val_tokens, val_labels = test_tokens[:500], test_labels[:500]\n",
    "# test_tokens, test_labels = test_tokens[500:], test_labels[:500]\n",
    "\n",
    "del IMDB_train_iter\n",
    "del IMDB_test_iter\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# if PRECOMPUTE_TOK_IDS:\n",
    "#   def save_tok_ids(all_tokens, filename_prefix, shard_size=5000):\n",
    "#     all_tok_ids = []\n",
    "#     for idx, tokens in tqdm(enumerate(all_tokens), total=len(all_tokens)):\n",
    "#       tok_ids = (batch_to_ids([tokens])[0])\n",
    "#       all_tok_ids.append(tok_ids)\n",
    "#\n",
    "#       if (idx + 1) % shard_size == 0 or (idx + 1) == len(all_tokens):\n",
    "#         torch.save(all_tok_ids, f\"{filename_prefix}{idx // shard_size}.pt\")\n",
    "#         del all_tok_ids\n",
    "#         gc.collect()\n",
    "#         all_tok_ids = []\n",
    "#     return all_tok_ids\n",
    "#\n",
    "#   train_filename_prefix = 'train_tok_ids'\n",
    "#   test_filename_prefix = 'test_tok_ids'\n",
    "#\n",
    "#   if not TOK_IDS_PRECOMPUTED:\n",
    "#     train_tok_ids = save_tok_ids(train_tokens, train_filename_prefix)\n",
    "#     del train_tokens\n",
    "#     gc.collect()\n",
    "#\n",
    "#     test_tok_ids = save_tok_ids(test_tokens, test_filename_prefix)\n",
    "#     del test_tokens\n",
    "#     gc.collect()\n",
    "#\n",
    "#\n",
    "#   class dataset(Dataset):\n",
    "#     def __init__(self, labels, filename_prefix, max_len, shard_size=5000):\n",
    "#       self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "#       self.length = self.labels.shape[0]\n",
    "#       self.filename_prefix = filename_prefix\n",
    "#       self.max_len = max_len\n",
    "#       self.shard_size=shard_size\n",
    "#       self.cur_shard = None\n",
    "#       self.cur_shard_idx = None\n",
    "#\n",
    "#     def __getitem__(self, idx):\n",
    "#       tok_ids = self.__get_tok_ids__(idx).to(device)\n",
    "#       if tok_ids.shape[0] > self.max_len:\n",
    "#         tok_ids = tok_ids[:self.max_len,:]\n",
    "#       else:\n",
    "#         zeros = torch.zeros((self.max_len - tok_ids.shape[0], 50), dtype=tok_ids.dtype, device=device)\n",
    "#         tok_ids = torch.concat((tok_ids, zeros))\n",
    "#\n",
    "#       return tok_ids.to(device), self.labels[idx].to(device)\n",
    "#\n",
    "#     def __get_tok_ids__(self, idx):\n",
    "#       self.__reload_shard__(idx)\n",
    "#       return self.cur_shard[idx % self.shard_size]\n",
    "#\n",
    "#     def __reload_shard__(self, idx):\n",
    "#       shard_idx = idx // self.shard_size\n",
    "#       if self.cur_shard_idx == shard_idx:\n",
    "#         return\n",
    "#\n",
    "#       del self.cur_shard\n",
    "#       gc.collect()\n",
    "#       self.cur_shard = torch.load(f\"{self.filename_prefix}{shard_idx}.pt\")\n",
    "#       self.cur_shard_idx = shard_idx\n",
    "#\n",
    "#     def __len__(self):\n",
    "#       return self.length\n",
    "#\n",
    "#\n",
    "#   trainset = dataset(train_labels, train_filename_prefix, MAX_SEQ_LEN)\n",
    "#   testset = dataset(test_labels, test_filename_prefix, MAX_SEQ_LEN)\n",
    "# else:\n",
    "class dataset(Dataset):\n",
    "  def __init__(self, tokens, labels):\n",
    "    self.tokens = tokens\n",
    "    self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    self.length = self.labels.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.tokens[idx], self.labels[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "\n",
    "\n",
    "trainset = dataset(train_tokens, train_labels)\n",
    "testset = dataset(test_tokens, test_labels)\n",
    "\n",
    "valset_size = int(len(testset) * 0.02)\n",
    "testset_size = len(testset) - valset_size\n",
    "valset = Subset(testset, range(valset_size))\n",
    "testset = Subset(testset, range(valset_size, valset_size + testset_size))\n",
    "\n",
    "class CollateBatch(object):\n",
    "  def __init__(self, batch_to_ids):\n",
    "    self.batch_to_ids = batch_to_ids\n",
    "\n",
    "  def __call__(self, batch):\n",
    "    tokens_batch, labels_batch = [tokens_and_label[0] for tokens_and_label in batch], [tokens_and_label[1] for tokens_and_label in batch]\n",
    "    tok_ids = self.batch_to_ids(tokens_batch).to(device)\n",
    "    labels_batch = torch.tensor(labels_batch, dtype=torch.float32, device=device)\n",
    "    return tok_ids, labels_batch\n",
    "\n",
    "collateBatch = CollateBatch(batch_to_ids)\n",
    "\n",
    "BATCH_SIZE = 6\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collateBatch)\n",
    "valloader = DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collateBatch)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collateBatch)"
   ],
   "metadata": {
    "id": "xT-BD8AIYdXK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UECEqirPD3_2"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self, embed_size, elmo):\n",
    "    super(Classifier, self).__init__()\n",
    "    self.embed_size = embed_size\n",
    "    self.elmo = elmo\n",
    "    self.fc1 = nn.Linear(embed_size, 1)\n",
    "    \n",
    "  def forward(self, input):\n",
    "    embs = self.elmo(input)['elmo_representations'][0]\n",
    "    mean = embs.mean(dim=1)\n",
    "    x = torch.sigmoid(self.fc1(mean))\n",
    "    return x\n",
    "\n",
    "\n",
    "if CLASSIFIER_PRETRAINED:\n",
    "  classifier = torch.load(PATH_TO_SAVE_ELMO_CLASSIFIER)\n",
    "else:\n",
    "  if IN_COLAB:\n",
    "    options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "    weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "  else:\n",
    "    options_file = \"options.json\"\n",
    "    weight_file = \"weights.hdf5\"\n",
    "  elmo = Elmo(options_file, weight_file, dropout=0, requires_grad=False, num_output_representations=1).to(device)\n",
    "  classifier = Classifier(1024, elmo=elmo).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in classifier.elmo.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "id": "kp9_BR9fYdXN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 1\n",
    "# l2_penalty = 0.001\n",
    "l2_penalty = 0\n",
    "\n",
    "optimizer = torch.optim.RMSprop(classifier.parameters(), lr=learning_rate, weight_decay=l2_penalty)\n",
    "loss_fn = F.binary_cross_entropy_with_logits"
   ],
   "metadata": {
    "id": "EHA4Iw4eYdXO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: torch>=1.3.1 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchmetrics) (1.12.1+cu113)\n",
      "Requirement already satisfied: numpy>=1.17.2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchmetrics) (1.23.4)\n",
      "Requirement already satisfied: packaging in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: typing-extensions in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\programs\\anaconda\\envs\\pmldl\\lib\\site-packages (from packaging->torchmetrics) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ],
   "metadata": {
    "id": "EKin9GVRYdXO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def eval_model(model, data, loss_fn):\n",
    "  acc_metric = torchmetrics.Accuracy().to(device)\n",
    "  prec_metric = torchmetrics.Precision().to(device)\n",
    "  rec_metric = torchmetrics.Recall().to(device)\n",
    "  f1_metric = torchmetrics.F1Score().to(device)\n",
    "  running_loss = 0\n",
    "  for x, y in tqdm(data):\n",
    "    with torch.no_grad():\n",
    "      y = y.reshape(-1, 1)\n",
    "      with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "        preds = model(x)\n",
    "        loss = loss_fn(preds, y)\n",
    "\n",
    "\n",
    "      running_loss += loss.item()\n",
    "      \n",
    "      y = y.type(torch.int8)\n",
    "      acc_metric(preds.round(), y)\n",
    "      prec_metric(preds.round(), y)\n",
    "      rec_metric(preds.round(), y)\n",
    "      f1_metric(preds.round(), y)\n",
    "\n",
    "      # print(y)\n",
    "      # print(preds.round())\n",
    "      # print(acc_metric.compute())\n",
    "\n",
    "  loss = running_loss / len(data)\n",
    "  acc = acc_metric.compute().item()\n",
    "  prec = prec_metric.compute().item()\n",
    "  rec = rec_metric.compute().item()\n",
    "  f1 = f1_metric.compute().item()\n",
    "  return loss, acc, prec, rec, f1\n",
    "\n",
    "# loss, acc, prec, rec, f1 = eval_model(classifier, valloader, loss_fn)\n",
    "# print(\"Initial metrics\\tval loss: {}\\tval acc: {}\\tval prec: {}\\tval rec: {}\\tval f1: {}\".format(loss, acc, prec, rec, f1))"
   ],
   "metadata": {
    "id": "1w1z74paYdXP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLvBW73M21-c",
    "outputId": "7eabc579-441e-4444-c026-56b760d84ee7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4167 [00:12<14:03:36, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 0\tloss: 0.977137565612793\tthis iteration loss: 0.977137565612793\taccuracy: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 51/4167 [05:31<7:59:54,  7.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 50\tloss: 0.7061653815063775\tthis iteration loss: 0.7873473167419434\taccuracy: 0.49019607843137253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 101/4167 [10:31<6:29:09,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 100\tloss: 0.6983277284272826\tthis iteration loss: 0.7133684158325195\taccuracy: 0.504950495049505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 151/4167 [15:55<5:35:05,  5.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 150\tloss: 0.6946744899086604\tthis iteration loss: 0.733524739742279\taccuracy: 0.5077262693156733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 201/4167 [20:50<7:45:53,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 200\tloss: 0.6915757709474706\tthis iteration loss: 0.6691860556602478\taccuracy: 0.511608623548922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 251/4167 [25:47<5:54:18,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 250\tloss: 0.6892048735542601\tthis iteration loss: 0.6892566680908203\taccuracy: 0.5239043824701195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 301/4167 [31:09<6:46:45,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 300\tloss: 0.6858527583141264\tthis iteration loss: 0.5863710641860962\taccuracy: 0.5332225913621262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 351/4167 [36:45<6:09:02,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 350\tloss: 0.6805021595581304\tthis iteration loss: 0.6318652629852295\taccuracy: 0.5489078822412156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 401/4167 [41:50<7:33:28,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 400\tloss: 0.6760530762392981\tthis iteration loss: 0.6494297981262207\taccuracy: 0.5631753948462178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 451/4167 [46:35<4:45:15,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 450\tloss: 0.6735029586667232\tthis iteration loss: 0.7610359191894531\taccuracy: 0.574648928307465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 501/4167 [51:27<7:12:32,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 500\tloss: 0.6732975340888886\tthis iteration loss: 0.635772705078125\taccuracy: 0.5798403193612774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 551/4167 [56:21<7:02:53,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 550\tloss: 0.6700989151823109\tthis iteration loss: 0.5313658118247986\taccuracy: 0.5831820931639443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 601/4167 [1:01:44<6:35:38,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 600\tloss: 0.6695641694767106\tthis iteration loss: 0.8004767298698425\taccuracy: 0.5904048807542984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 651/4167 [1:06:58<6:06:55,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 650\tloss: 0.6680788634467967\tthis iteration loss: 0.6173998713493347\taccuracy: 0.601126472094214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 701/4167 [1:11:32<5:24:04,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 700\tloss: 0.6660108682347432\tthis iteration loss: 0.6577993035316467\taccuracy: 0.6077032810271041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 751/4167 [1:16:30<5:24:43,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 750\tloss: 0.6642427365884641\tthis iteration loss: 0.552340030670166\taccuracy: 0.6154016866400355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 801/4167 [1:22:10<6:51:45,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 800\tloss: 0.6635672919610318\tthis iteration loss: 0.7144010066986084\taccuracy: 0.6186017478152309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 851/4167 [1:27:36<7:41:31,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 850\tloss: 0.662641859012541\tthis iteration loss: 0.5652734041213989\taccuracy: 0.6214257735996866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 901/4167 [1:32:48<5:56:03,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 900\tloss: 0.6610860550046364\tthis iteration loss: 0.651819109916687\taccuracy: 0.6267110617832038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 951/4167 [1:37:39<5:47:17,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 950\tloss: 0.6604312079812701\tthis iteration loss: 0.7882561087608337\taccuracy: 0.632316859446197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1001/4167 [1:42:47<5:21:48,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1000\tloss: 0.6595263288214014\tthis iteration loss: 0.6595432758331299\taccuracy: 0.6350316350316351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1051/4167 [1:48:02<4:24:32,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1050\tloss: 0.6583918880894567\tthis iteration loss: 0.6944688558578491\taccuracy: 0.6374881065651761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 1101/4167 [1:52:59<5:17:09,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1100\tloss: 0.6564756291330565\tthis iteration loss: 0.621554970741272\taccuracy: 0.641537995761429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1151/4167 [1:58:27<5:58:27,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1150\tloss: 0.6549104529034045\tthis iteration loss: 0.5787568092346191\taccuracy: 0.6471184477266145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1201/4167 [2:03:17<4:30:40,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1200\tloss: 0.6547977781911178\tthis iteration loss: 0.8058728575706482\taccuracy: 0.6520954759922287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1251/4167 [2:08:38<5:34:47,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1250\tloss: 0.6536625624179458\tthis iteration loss: 0.6596800684928894\taccuracy: 0.6562749800159872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1301/4167 [2:15:10<5:43:10,  7.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1300\tloss: 0.6515640623976321\tthis iteration loss: 0.5570120215415955\taccuracy: 0.6598770176787087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1351/4167 [2:20:30<4:05:04,  5.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1350\tloss: 0.65057745650907\tthis iteration loss: 0.5762374401092529\taccuracy: 0.6633358006415001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 1401/4167 [2:25:29<4:23:24,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1400\tloss: 0.6491626889938801\tthis iteration loss: 0.5686429738998413\taccuracy: 0.6682131810611468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 1451/4167 [2:34:50<4:24:46,  5.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1450\tloss: 0.6486556313926807\tthis iteration loss: 0.5552093982696533\taccuracy: 0.6714909257983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1501/4167 [2:39:47<4:54:45,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1500\tloss: 0.6482674967321375\tthis iteration loss: 0.4611329734325409\taccuracy: 0.6742171885409727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1551/4167 [2:44:52<3:44:18,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1550\tloss: 0.6474197392575899\tthis iteration loss: 0.621996283531189\taccuracy: 0.6761229314420804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1601/4167 [2:50:27<4:11:34,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1600\tloss: 0.646567492578865\tthis iteration loss: 0.5352944135665894\taccuracy: 0.6782219446179472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1651/4167 [2:56:03<5:07:46,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1650\tloss: 0.6455045433783806\tthis iteration loss: 0.5609873533248901\taccuracy: 0.6813042600444176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1701/4167 [3:00:47<5:11:41,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1700\tloss: 0.6441761740406144\tthis iteration loss: 0.7271756529808044\taccuracy: 0.6837154614932393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1751/4167 [3:05:30<4:18:54,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1750\tloss: 0.6436686617418537\tthis iteration loss: 0.675286054611206\taccuracy: 0.6857985912811727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1801/4167 [3:11:27<4:57:47,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1800\tloss: 0.6428145585888826\tthis iteration loss: 0.7485710978507996\taccuracy: 0.686933185267444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1851/4167 [3:16:11<3:30:33,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1850\tloss: 0.6419419270151696\tthis iteration loss: 0.7201981544494629\taccuracy: 0.6893571042679633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 1901/4167 [3:21:07<3:23:38,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1900\tloss: 0.6414879697175605\tthis iteration loss: 0.6919854879379272\taccuracy: 0.6906891109942136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1951/4167 [3:26:27<3:23:47,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 1950\tloss: 0.6406565554504942\tthis iteration loss: 0.5018265843391418\taccuracy: 0.692636254912011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2001/4167 [3:31:23<2:50:28,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2000\tloss: 0.6398154963617739\tthis iteration loss: 0.5308161973953247\taccuracy: 0.6957354656005331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2051/4167 [3:36:35<2:48:38,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2050\tloss: 0.6396172885805267\tthis iteration loss: 0.6471821069717407\taccuracy: 0.6973833902161547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2101/4167 [3:41:25<3:05:11,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2100\tloss: 0.6388627196538454\tthis iteration loss: 0.6997742652893066\taccuracy: 0.6996668253212756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2151/4167 [3:46:28<3:12:42,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2150\tloss: 0.638046925647599\tthis iteration loss: 0.5832899212837219\taccuracy: 0.7016116534944987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2201/4167 [3:51:44<3:03:01,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2200\tloss: 0.6371712979134079\tthis iteration loss: 0.7232033610343933\taccuracy: 0.7037710131758291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2251/4167 [3:56:50<3:10:26,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2250\tloss: 0.6364424679608729\tthis iteration loss: 0.662787139415741\taccuracy: 0.7056863616170591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2301/4167 [4:01:27<2:43:48,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2300\tloss: 0.6358905632513495\tthis iteration loss: 0.6066322922706604\taccuracy: 0.7072287411270463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 2351/4167 [4:07:20<3:31:03,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2350\tloss: 0.6351730493929274\tthis iteration loss: 0.6397579908370972\taccuracy: 0.7092726499361973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2401/4167 [4:13:37<3:00:21,  6.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2400\tloss: 0.6346569330133234\tthis iteration loss: 0.7373355627059937\taccuracy: 0.7106761071775649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 2451/4167 [4:18:51<2:36:35,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2450\tloss: 0.6342481546793992\tthis iteration loss: 0.6484643816947937\taccuracy: 0.7118183054535564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2501/4167 [4:23:47<2:00:59,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2500\tloss: 0.6332544677975368\tthis iteration loss: 0.46458810567855835\taccuracy: 0.713181394109023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 2551/4167 [4:28:21<2:35:44,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2550\tloss: 0.6322860704572095\tthis iteration loss: 0.5402002334594727\taccuracy: 0.7148177185417484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 2601/4167 [4:33:11<2:48:53,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2600\tloss: 0.6317365875339471\tthis iteration loss: 0.7020460367202759\taccuracy: 0.7166474432910419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 2651/4167 [4:38:21<2:07:38,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\titeration: 2650\tloss: 0.6309566563118273\tthis iteration loss: 0.4408737123012543\taccuracy: 0.7183452785112536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2657/4167 [4:39:04<3:05:09,  7.36s/it]"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_metrics = []\n",
    "\n",
    "best_val_loss = 1e+8\n",
    "for epoch in range(epochs):\n",
    "  running_loss, correct, total = 0, 0, 0\n",
    "  for iteration, (x_train ,y_train) in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "    optimizer.zero_grad()\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "      preds = classifier(x_train)\n",
    "      loss = loss_fn(preds, y_train)\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    total += y_train.shape[0]\n",
    "    correct += preds.round().eq(y_train).sum().item()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iteration % 50 == 0:\n",
    "      _loss = running_loss / (iteration + 1)\n",
    "      acc = correct / total\n",
    "      print(\"epoch: {}\\titeration: {}\\tloss: {}\\tthis iteration loss: {}\\taccuracy: {}\".format(epoch, iteration, _loss, loss, acc))\n",
    "\n",
    "\n",
    "  loss = running_loss / len(trainloader)\n",
    "  acc = correct / total\n",
    "  train_losses.append(loss)\n",
    "  train_accs.append(acc)\n",
    "  print(\"epoch {}\\ttrain loss : {}\\ttrain accuracy : {}\".format(epoch, loss, acc))\n",
    "\n",
    "  loss, acc, prec, rec, f1 = eval_model(classifier, valloader, loss_fn)\n",
    "  val_metrics.append([loss, acc, prec, rec, f1])\n",
    "  print(\"epoch: {}\\tval loss: {}\\tval acc: {}\\tval prec: {}\\tval rec: {}\\tval f1: {}\".format(epoch, loss, acc, prec, rec, f1))\n",
    "  if best_val_loss > loss:\n",
    "    torch.save(classifier, PATH_TO_SAVE_ELMO_CLASSIFIER)\n",
    "    best_val_loss = loss\n",
    "  if not IN_COLAB:\n",
    "    torch.save(classifier, f'classifier{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  !kill $(ps aux | awk '{print $2}')"
   ],
   "metadata": {
    "id": "fNyFSp2wYdXQ",
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
