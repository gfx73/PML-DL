{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gfx73/PML-DL/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AD-HO1iDuN8y",
        "outputId": "e94e330c-341c-4205-f1a4-96e7392a2f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting allennlp\n",
            "  Downloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n",
            "\u001b[K     |████████████████████████████████| 730 kB 17.6 MB/s \n",
            "\u001b[?25hCollecting requests>=2.28\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting fairscale==0.4.6\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 56.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.64.1)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.3.6)\n",
            "Collecting transformers<4.21,>=4.1\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 58.0 MB/s \n",
            "\u001b[?25hCollecting base58>=2.1.1\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.0.2)\n",
            "Collecting traitlets>5.1.1\n",
            "  Downloading traitlets-5.5.0-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 70.8 MB/s \n",
            "\u001b[?25hCollecting pytest>=6.2.5\n",
            "  Downloading pytest-7.2.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 64.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (9.0.0)\n",
            "Collecting termcolor==1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting h5py>=3.6.0\n",
            "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 62.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 59.2 MB/s \n",
            "\u001b[?25hCollecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 64.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.21.6)\n",
            "Collecting filelock<3.8,>=3.3\n",
            "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch<1.13.0,>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.12.1+cu113)\n",
            "Collecting cached-path<1.2.0,>=1.1.3\n",
            "  Downloading cached_path-1.1.6-py3-none-any.whl (26 kB)\n",
            "Collecting huggingface-hub>=0.0.16\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 60.5 MB/s \n",
            "\u001b[?25hCollecting wandb<0.13.0,>=0.10.0\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision<0.14.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.13.1+cu113)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.7)\n",
            "Collecting lmdb>=1.2.1\n",
            "  Downloading lmdb-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting spacy<3.4,>=2.1.0\n",
            "  Downloading spacy-3.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.4.2)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.17.3)\n",
            "Collecting sentencepiece>=0.1.96\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 57.2 MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.0\n",
            "  Downloading boto3-1.26.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 70.2 MB/s \n",
            "\u001b[?25hCollecting google-cloud-storage<3.0,>=1.32.0\n",
            "  Downloading google_cloud_storage-2.5.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 73.7 MB/s \n",
            "\u001b[?25hCollecting rich<13.0,>=12.1\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 74.5 MB/s \n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.0\n",
            "  Downloading botocore-1.29.0-py3-none-any.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 60.8 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 72.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.0->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.8.2)\n",
            "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
            "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.31.6)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.35.0)\n",
            "Collecting google-resumable-media>=2.3.2\n",
            "  Downloading google_resumable_media-2.4.0-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.15.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (21.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.56.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2022.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.2.8)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.8)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->allennlp) (22.1.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting exceptiongroup>=1.0.0rc8\n",
            "  Downloading exceptiongroup-1.0.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.0.16->allennlp) (3.10.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp) (2022.9.24)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.1.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.6.2)\n",
            "Collecting thinc<8.1.0,>=8.0.14\n",
            "  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 64.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.5)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.3)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4,>=2.1.0->allennlp) (5.2.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (7.1.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 60.3 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 74.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.0.1)\n",
            "Building wheels for collected packages: fairscale, termcolor, jsonnet, pathtools, sacremoses\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307252 sha256=a1984bb51d6c0916affdf4afdb63d6940909bd2133e5db1b3a1eaefe9b561f1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=e50ff7fcfe8864bf2ed6ae87c3c5f6b14268c1b8f1fc21b4b360e696e65714f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp37-cp37m-linux_x86_64.whl size=3997198 sha256=1a34e4f0015842cf62a8958031f976f9a0e5e169f00cfb3d38de5718234b3efa\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/6b/48/a168ed5f8d01c50268605eff341c29126286763607bf707e3b\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=994802b734debd5ea7e158ca0ee0f06918e8ac1633dfeb48fc4dee3076bc1f22\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=30e4d54adfee9e2789cf8dd6c297c97a7a7f6e81903bd19423a01dae049c691c\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built fairscale termcolor jsonnet pathtools sacremoses\n",
            "Installing collected packages: urllib3, requests, jmespath, smmap, google-crc32c, botocore, s3transfer, pydantic, google-resumable-media, google-cloud-core, gitdb, filelock, commonmark, tokenizers, thinc, shortuuid, setproctitle, sentry-sdk, rich, pluggy, pathtools, iniconfig, huggingface-hub, google-cloud-storage, GitPython, exceptiongroup, docker-pycreds, boto3, wandb, transformers, traitlets, termcolor, tensorboardX, spacy, sentencepiece, sacremoses, pytest, lmdb, jsonnet, h5py, fairscale, cached-path, base58, allennlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.2\n",
            "    Uninstalling pydantic-1.10.2:\n",
            "      Successfully uninstalled pydantic-1.10.2\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.8.0\n",
            "    Uninstalling filelock-3.8.0:\n",
            "      Successfully uninstalled filelock-3.8.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.5\n",
            "    Uninstalling thinc-8.1.5:\n",
            "      Successfully uninstalled thinc-8.1.5\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.1.1\n",
            "    Uninstalling traitlets-5.1.1:\n",
            "      Successfully uninstalled traitlets-5.1.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.0.1\n",
            "    Uninstalling termcolor-2.0.1:\n",
            "      Successfully uninstalled termcolor-2.0.1\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.2\n",
            "    Uninstalling spacy-3.4.2:\n",
            "      Successfully uninstalled spacy-3.4.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: lmdb\n",
            "    Found existing installation: lmdb 0.99\n",
            "    Uninstalling lmdb-0.99:\n",
            "      Successfully uninstalled lmdb-0.99\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.2 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.4.0 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.29 allennlp-2.10.1 base58-2.1.1 boto3-1.26.0 botocore-1.29.0 cached-path-1.1.6 commonmark-0.9.1 docker-pycreds-0.4.0 exceptiongroup-1.0.0 fairscale-0.4.6 filelock-3.7.1 gitdb-4.0.9 google-cloud-core-2.3.2 google-cloud-storage-2.5.0 google-crc32c-1.5.0 google-resumable-media-2.4.0 h5py-3.7.0 huggingface-hub-0.10.1 iniconfig-1.1.1 jmespath-1.0.1 jsonnet-0.19.1 lmdb-1.3.0 pathtools-0.1.2 pluggy-1.0.0 pydantic-1.8.2 pytest-7.2.0 requests-2.28.1 rich-12.6.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 sentry-sdk-1.10.1 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 spacy-3.3.1 tensorboardX-2.5.1 termcolor-1.1.0 thinc-8.0.17 tokenizers-0.12.1 traitlets-5.5.0 transformers-4.20.1 urllib3-1.26.12 wandb-0.12.21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install allennlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8OFl6YZUbxK",
        "outputId": "8450263f-3dd3-4ed7-8b9f-84aa611bb1bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch==1.12.1+cu113 in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision==0.13.1+cu113 in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio==0.12.1 in /usr/local/lib/python3.7/dist-packages (0.12.1+cu113)\n",
            "Collecting torchdata==0.4.1\n",
            "  Downloading torchdata-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 19.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchtext==0.13.1 in /usr/local/lib/python3.7/dist-packages (0.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1+cu113) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.13.1+cu113) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.13.1+cu113) (2.28.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.13.1+cu113) (7.1.2)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata==0.4.1) (1.26.12)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.1) (4.64.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1+cu113) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1+cu113) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.1+cu113) (2022.9.24)\n",
            "Installing collected packages: portalocker, torchdata\n",
            "Successfully installed portalocker-2.6.0 torchdata-0.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 torchdata==0.4.1 torchtext==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "import sys\n",
        "CLASSIFIER_PRETRAINED = False\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "  PATH_TO_SAVE_ELMO_CLASSIFIER = '/content/drive/MyDrive/PML&DL/Assignment2/elmo_classifier.pt'\n",
        "else:\n",
        "  PATH_TO_SAVE_ELMO_CLASSIFIER = 'elmo_classifier.pt'"
      ],
      "metadata": {
        "id": "1lUn0gjBYdXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JXDZ44Uvc_P3",
        "outputId": "8a0d7cd5-d426-4fc0-b4d0-778d164188af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ADLyYv5gTXie"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "\n",
        "IMDB_train_iter, IMDB_test_iter = IMDB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MacnAo18Tci1",
        "outputId": "3dd00e98-8ac1-4b08-efff-6d69ea4f4520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [00:30, 824.96it/s] \n",
            "25000it [00:16, 1559.43it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import gc\n",
        "import random\n",
        "\n",
        "\n",
        "random.seed(11)\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def get_labels_and_text(datasplit):\n",
        "  tokens, labels = [], []\n",
        "  for label, text in tqdm(datasplit):\n",
        "    tokens.append(tokenizer(text))\n",
        "    labels.append(label=='pos')\n",
        "  return tokens, labels\n",
        "\n",
        "train_tokens, train_labels = get_labels_and_text(IMDB_train_iter)\n",
        "test_tokens, test_labels = get_labels_and_text(IMDB_test_iter)\n",
        "\n",
        "sample_tokens_and_labels = lambda tokens, labels: zip(*random.sample(list(zip(tokens, labels)), len(labels)))\n",
        "\n",
        "train_tokens, train_labels = sample_tokens_and_labels(train_tokens, train_labels)\n",
        "test_tokens, test_labels = sample_tokens_and_labels(test_tokens, test_labels)\n",
        "\n",
        "# val_tokens, val_labels = test_tokens[:500], test_labels[:500]\n",
        "# test_tokens, test_labels = test_tokens[500:], test_labels[:500]\n",
        "\n",
        "del IMDB_train_iter\n",
        "del IMDB_test_iter\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# if PRECOMPUTE_TOK_IDS:\n",
        "#   def save_tok_ids(all_tokens, filename_prefix, shard_size=5000):\n",
        "#     all_tok_ids = []\n",
        "#     for idx, tokens in tqdm(enumerate(all_tokens), total=len(all_tokens)):\n",
        "#       tok_ids = (batch_to_ids([tokens])[0])\n",
        "#       all_tok_ids.append(tok_ids)\n",
        "#\n",
        "#       if (idx + 1) % shard_size == 0 or (idx + 1) == len(all_tokens):\n",
        "#         torch.save(all_tok_ids, f\"{filename_prefix}{idx // shard_size}.pt\")\n",
        "#         del all_tok_ids\n",
        "#         gc.collect()\n",
        "#         all_tok_ids = []\n",
        "#     return all_tok_ids\n",
        "#\n",
        "#   train_filename_prefix = 'train_tok_ids'\n",
        "#   test_filename_prefix = 'test_tok_ids'\n",
        "#\n",
        "#   if not TOK_IDS_PRECOMPUTED:\n",
        "#     train_tok_ids = save_tok_ids(train_tokens, train_filename_prefix)\n",
        "#     del train_tokens\n",
        "#     gc.collect()\n",
        "#\n",
        "#     test_tok_ids = save_tok_ids(test_tokens, test_filename_prefix)\n",
        "#     del test_tokens\n",
        "#     gc.collect()\n",
        "#\n",
        "#\n",
        "#   class dataset(Dataset):\n",
        "#     def __init__(self, labels, filename_prefix, max_len, shard_size=5000):\n",
        "#       self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "#       self.length = self.labels.shape[0]\n",
        "#       self.filename_prefix = filename_prefix\n",
        "#       self.max_len = max_len\n",
        "#       self.shard_size=shard_size\n",
        "#       self.cur_shard = None\n",
        "#       self.cur_shard_idx = None\n",
        "#\n",
        "#     def __getitem__(self, idx):\n",
        "#       tok_ids = self.__get_tok_ids__(idx).to(device)\n",
        "#       if tok_ids.shape[0] > self.max_len:\n",
        "#         tok_ids = tok_ids[:self.max_len,:]\n",
        "#       else:\n",
        "#         zeros = torch.zeros((self.max_len - tok_ids.shape[0], 50), dtype=tok_ids.dtype, device=device)\n",
        "#         tok_ids = torch.concat((tok_ids, zeros))\n",
        "#\n",
        "#       return tok_ids.to(device), self.labels[idx].to(device)\n",
        "#\n",
        "#     def __get_tok_ids__(self, idx):\n",
        "#       self.__reload_shard__(idx)\n",
        "#       return self.cur_shard[idx % self.shard_size]\n",
        "#\n",
        "#     def __reload_shard__(self, idx):\n",
        "#       shard_idx = idx // self.shard_size\n",
        "#       if self.cur_shard_idx == shard_idx:\n",
        "#         return\n",
        "#\n",
        "#       del self.cur_shard\n",
        "#       gc.collect()\n",
        "#       self.cur_shard = torch.load(f\"{self.filename_prefix}{shard_idx}.pt\")\n",
        "#       self.cur_shard_idx = shard_idx\n",
        "#\n",
        "#     def __len__(self):\n",
        "#       return self.length\n",
        "#\n",
        "#\n",
        "#   trainset = dataset(train_labels, train_filename_prefix, MAX_SEQ_LEN)\n",
        "#   testset = dataset(test_labels, test_filename_prefix, MAX_SEQ_LEN)\n",
        "# else:\n",
        "class dataset(Dataset):\n",
        "  def __init__(self, tokens, labels):\n",
        "    self.tokens = tokens\n",
        "    self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "    self.length = self.labels.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.tokens[idx], self.labels[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "\n",
        "trainset = dataset(train_tokens, train_labels)\n",
        "testset = dataset(test_tokens, test_labels)\n",
        "\n",
        "valset_size = int(len(testset) * 0.02)\n",
        "testset_size = len(testset) - valset_size\n",
        "valset = Subset(testset, range(valset_size))\n",
        "testset = Subset(testset, range(valset_size, valset_size + testset_size))\n",
        "\n",
        "class CollateBatch(object):\n",
        "  def __init__(self, batch_to_ids):\n",
        "    self.batch_to_ids = batch_to_ids\n",
        "\n",
        "  def __call__(self, batch):\n",
        "    tokens_batch, labels_batch = [tokens_and_label[0] for tokens_and_label in batch], [tokens_and_label[1] for tokens_and_label in batch]\n",
        "    tok_ids = self.batch_to_ids(tokens_batch).to(device)\n",
        "    labels_batch = torch.tensor(labels_batch, dtype=torch.float32, device=device)\n",
        "    return tok_ids, labels_batch\n",
        "\n",
        "collateBatch = CollateBatch(batch_to_ids)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collateBatch)\n",
        "valloader = DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collateBatch)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collateBatch)"
      ],
      "metadata": {
        "id": "xT-BD8AIYdXK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UECEqirPD3_2",
        "outputId": "46cd8494-a8e8-4711-dd56-57740f110f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0821c46acae84ba3a60eaae2bd8786eb",
            "98de5dcc58d94bc09cf7befbaf581737",
            "fcf0231c34fa46e39c5bb5937321c642",
            "ebf50a85531a436bb3333b3d1ac6baea"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0821c46acae84ba3a60eaae2bd8786eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcf0231c34fa46e39c5bb5937321c642"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, embed_size, elmo):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.elmo = elmo\n",
        "    self.fc1 = nn.Linear(embed_size, 1)\n",
        "    \n",
        "  def forward(self, input):\n",
        "    embs = self.elmo(input)['elmo_representations'][0]\n",
        "    mean = embs.mean(dim=1)\n",
        "    x = torch.sigmoid(self.fc1(mean))\n",
        "    return x\n",
        "\n",
        "\n",
        "if CLASSIFIER_PRETRAINED:\n",
        "  classifier = torch.load(PATH_TO_SAVE_ELMO_CLASSIFIER)\n",
        "else:\n",
        "  if IN_COLAB:\n",
        "    options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "    weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "  else:\n",
        "    options_file = \"options.json\"\n",
        "    weight_file = \"weights.hdf5\"\n",
        "  elmo = Elmo(options_file, weight_file, dropout=0, requires_grad=False, num_output_representations=1).to(device)\n",
        "  classifier = Classifier(1024, elmo=elmo).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "sum(p.numel() for p in classifier.elmo.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "kp9_BR9fYdXN",
        "outputId": "b142f688-a696-4aea-f9bb-a9f847b069db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": [
        "learning_rate = 0.003\n",
        "epochs = 1\n",
        "# l2_penalty = 0.001\n",
        "l2_penalty = 0\n",
        "\n",
        "optimizer = torch.optim.RMSprop(classifier.parameters(), lr=learning_rate, weight_decay=l2_penalty)\n",
        "loss_fn = F.binary_cross_entropy_with_logits"
      ],
      "metadata": {
        "id": "EHA4Iw4eYdXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 30.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "EKin9GVRYdXO",
        "outputId": "057cd96e-24c4-480b-c94f-f1349a9b4935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "\n",
        "def eval_model(model, data, loss_fn):\n",
        "  acc_metric = torchmetrics.Accuracy().to(device)\n",
        "  prec_metric = torchmetrics.Precision().to(device)\n",
        "  rec_metric = torchmetrics.Recall().to(device)\n",
        "  f1_metric = torchmetrics.F1Score().to(device)\n",
        "  running_loss = 0\n",
        "  for x, y in tqdm(data):\n",
        "    with torch.no_grad():\n",
        "      y = y.reshape(-1, 1)\n",
        "      with torch.autocast(device_type=device, dtype=torch.float16):\n",
        "        preds = model(x)\n",
        "        loss = loss_fn(preds, y)\n",
        "\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      \n",
        "      y = y.type(torch.int8)\n",
        "      acc_metric(preds.round(), y)\n",
        "      prec_metric(preds.round(), y)\n",
        "      rec_metric(preds.round(), y)\n",
        "      f1_metric(preds.round(), y)\n",
        "\n",
        "      # print(y)\n",
        "      # print(preds.round())\n",
        "      # print(acc_metric.compute())\n",
        "\n",
        "  loss = running_loss / len(data)\n",
        "  acc = acc_metric.compute().item()\n",
        "  prec = prec_metric.compute().item()\n",
        "  rec = rec_metric.compute().item()\n",
        "  f1 = f1_metric.compute().item()\n",
        "  return loss, acc, prec, rec, f1\n",
        "\n",
        "# loss, acc, prec, rec, f1 = eval_model(classifier, valloader, loss_fn)\n",
        "# print(\"Initial metrics\\tval loss: {}\\tval acc: {}\\tval prec: {}\\tval rec: {}\\tval f1: {}\".format(loss, acc, prec, rec, f1))"
      ],
      "metadata": {
        "id": "1w1z74paYdXP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLvBW73M21-c",
        "outputId": "0ae94180-7103-4bce-a7a6-3ead2d623ffe",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/782 [00:07<1:32:22,  7.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 0\tloss: 0.6283023357391357\tthis iteration loss: 0.6283023357391357\taccuracy: 0.78125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 51/782 [02:48<34:46,  2.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 50\tloss: 0.6828417275466171\tthis iteration loss: 0.6961194276809692\taccuracy: 0.5490196078431373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 101/782 [05:36<38:19,  3.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 100\tloss: 0.673536499538044\tthis iteration loss: 0.6901473999023438\taccuracy: 0.5962252475247525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 151/782 [08:32<42:03,  4.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 150\tloss: 0.662827395050731\tthis iteration loss: 0.5992738604545593\taccuracy: 0.6276903973509934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 201/782 [11:18<34:09,  3.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 200\tloss: 0.6553210992718217\tthis iteration loss: 0.6513580083847046\taccuracy: 0.6449004975124378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 251/782 [14:08<30:16,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 250\tloss: 0.6500494074061572\tthis iteration loss: 0.6181433200836182\taccuracy: 0.6655876494023905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 301/782 [17:00<30:57,  3.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 300\tloss: 0.6445627172919999\tthis iteration loss: 0.6432056427001953\taccuracy: 0.6795058139534884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 351/782 [19:40<25:45,  3.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 350\tloss: 0.6408058236806821\tthis iteration loss: 0.5683448314666748\taccuracy: 0.6915064102564102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████▏    | 401/782 [22:46<21:07,  3.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 400\tloss: 0.6372700468857687\tthis iteration loss: 0.6406313180923462\taccuracy: 0.6993453865336658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 451/782 [25:31<18:53,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 450\tloss: 0.63376255627482\tthis iteration loss: 0.6117323040962219\taccuracy: 0.7084950110864745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 501/782 [28:19<19:13,  4.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 500\tloss: 0.6316656812936247\tthis iteration loss: 0.6761535406112671\taccuracy: 0.7153817365269461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 551/782 [31:22<12:21,  3.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 550\tloss: 0.6297325337214392\tthis iteration loss: 0.5612467527389526\taccuracy: 0.7206783121597096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 601/782 [34:07<08:21,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 600\tloss: 0.6277472713029325\tthis iteration loss: 0.6071460843086243\taccuracy: 0.7255615640599001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 651/782 [37:07<07:25,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 650\tloss: 0.6259071945960987\tthis iteration loss: 0.6241366267204285\taccuracy: 0.7307027649769585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 701/782 [39:57<04:08,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 700\tloss: 0.623754105537322\tthis iteration loss: 0.6158937215805054\taccuracy: 0.734218972895863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 751/782 [43:02<01:49,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 750\tloss: 0.6216627938372794\tthis iteration loss: 0.5869169235229492\taccuracy: 0.7382656458055925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [44:54<00:00,  3.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\ttrain loss : 0.6209402933831105\ttrain accuracy : 0.7414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:47<00:00,  2.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\tval loss: 0.5759647786617279\tval acc: 0.7940000295639038\tval prec: 0.8930232524871826\tval rec: 0.7058823704719543\tval f1: 0.7885010838508606\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "# torch.autograd.set_detect_anomaly(True)\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_metrics = []\n",
        "\n",
        "best_val_loss = 1e+8\n",
        "for epoch in range(epochs):\n",
        "  running_loss, correct, total = 0, 0, 0\n",
        "  for iteration, (x_train ,y_train) in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
        "    optimizer.zero_grad()\n",
        "    y_train = y_train.reshape(-1,1)\n",
        "    with torch.autocast(device_type=device, dtype=torch.float16):\n",
        "      preds = classifier(x_train)\n",
        "      loss = loss_fn(preds, y_train)\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    total += y_train.shape[0]\n",
        "    correct += preds.round().eq(y_train).sum().item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iteration % 50 == 0:\n",
        "      _loss = running_loss / (iteration + 1)\n",
        "      acc = correct / total\n",
        "      print(\"epoch: {}\\titeration: {}\\tloss: {}\\tthis iteration loss: {}\\taccuracy: {}\".format(epoch, iteration, _loss, loss, acc))\n",
        "\n",
        "\n",
        "  loss = running_loss / len(trainloader)\n",
        "  acc = correct / total\n",
        "  train_losses.append(loss)\n",
        "  train_accs.append(acc)\n",
        "  print(\"epoch {}\\ttrain loss : {}\\ttrain accuracy : {}\".format(epoch, loss, acc))\n",
        "\n",
        "  loss, acc, prec, rec, f1 = eval_model(classifier, valloader, loss_fn)\n",
        "  val_metrics.append([loss, acc, prec, rec, f1])\n",
        "  print(\"epoch: {}\\tval loss: {}\\tval acc: {}\\tval prec: {}\\tval rec: {}\\tval f1: {}\".format(epoch, loss, acc, prec, rec, f1))\n",
        "  if best_val_loss > loss:\n",
        "    torch.save(classifier, PATH_TO_SAVE_ELMO_CLASSIFIER)\n",
        "    best_val_loss = loss\n",
        "  if not IN_COLAB:\n",
        "    torch.save(classifier, f'classifier{epoch}.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  !kill $(ps aux | awk '{print $2}')"
      ],
      "metadata": {
        "id": "fNyFSp2wYdXQ",
        "pycharm": {
          "is_executing": true
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0821c46acae84ba3a60eaae2bd8786eb": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_98de5dcc58d94bc09cf7befbaf581737",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Downloading \u001b[3;36mhttps://s3-us-west-2.amazonaws.com/allennlp/model…\u001b[0m \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m0/336 bytes\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Downloading <span style=\"color: #008080; text-decoration-color: #008080; font-style: italic\">https://s3-us-west-2.amazonaws.com/allennlp/model…</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> <span style=\"color: #008000; text-decoration-color: #008000\">0/336 bytes</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "98de5dcc58d94bc09cf7befbaf581737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf0231c34fa46e39c5bb5937321c642": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ebf50a85531a436bb3333b3d1ac6baea",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Downloading \u001b[3;36mhttps://s3-us-west-2.amazonaws.com/allennlp/model…\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[35m 99%\u001b[0m \u001b[33m0:00:29\u001b[0m \u001b[32m372.4/374.4 MB\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Downloading <span style=\"color: #008080; text-decoration-color: #008080; font-style: italic\">https://s3-us-west-2.amazonaws.com/allennlp/model…</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 99%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:29</span> <span style=\"color: #008000; text-decoration-color: #008000\">372.4/374.4 MB</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "ebf50a85531a436bb3333b3d1ac6baea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}